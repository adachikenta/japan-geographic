"""
å…¨å›½ã®å¸‚åŒºç”ºæ‘å½¹å ´åº§æ¨™ã‚’çµ±åˆæŠ½å‡º

å›½åœŸæ•°å€¤æƒ…å ± P34-14 (2014å¹´åº¦) å…¨47éƒ½é“åºœçœŒãƒ‡ãƒ¼ã‚¿ã‚’å‡¦ç†
"""
import geopandas as gpd
import pandas as pd
import zipfile
import os
from pathlib import Path

GML_DIR = Path('C:/repos/japan-geographic/GML')
OUTPUT_DIR = Path('C:/repos/japan-geographic/data/processing')

def extract_all_zips():
    """å…¨zipãƒ•ã‚¡ã‚¤ãƒ«ã‚’è§£å‡"""
    print("=" * 70)
    print("ZIPè§£å‡å‡¦ç†é–‹å§‹")
    print("=" * 70)

    zip_files = sorted(GML_DIR.glob('P34-14_*.zip'))
    print(f"ğŸ“¦ {len(zip_files)}å€‹ã®zipãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ¤œå‡º\n")

    extract_dir = GML_DIR / 'extracted'
    extract_dir.mkdir(exist_ok=True)

    for zip_path in zip_files:
        pref_num = zip_path.stem.split('_')[1]
        pref_dir = extract_dir / f'P34-14_{pref_num}_GML'

        if pref_dir.exists():
            print(f"â­ï¸  {zip_path.name} - æ—¢ã«è§£å‡æ¸ˆã¿")
            continue

        print(f"ğŸ“‚ {zip_path.name} ã‚’è§£å‡ä¸­...")
        try:
            with zipfile.ZipFile(zip_path, 'r') as zip_ref:
                zip_ref.extractall(pref_dir)
            print(f"   âœ“ å®Œäº†")
        except Exception as e:
            print(f"   âœ— ã‚¨ãƒ©ãƒ¼: {e}")

    print(f"\nâœ… è§£å‡å®Œäº†: {extract_dir}\n")
    return extract_dir

def extract_coordinates_from_shapefiles(extract_dir):
    """å…¨Shapefileã‹ã‚‰åº§æ¨™ã‚’æŠ½å‡º"""
    print("=" * 70)
    print("Shapefileåº§æ¨™æŠ½å‡º")
    print("=" * 70)

    all_data = []

    # å„éƒ½é“åºœçœŒãƒ•ã‚©ãƒ«ãƒ€ã‚’å‡¦ç†
    pref_dirs = sorted(extract_dir.glob('P34-14_*_GML'))

    for pref_dir in pref_dirs:
        shp_files = list(pref_dir.glob('*.shp'))

        if not shp_files:
            print(f"âš ï¸  {pref_dir.name}: Shapefileãªã—")
            continue

        shp_path = shp_files[0]
        pref_num = pref_dir.name.split('_')[1]

        try:
            gdf = gpd.read_file(shp_path, encoding='shift-jis')
            print(f"âœ“ {pref_dir.name}: {len(gdf)}ä»¶ã®ãƒ‡ãƒ¼ã‚¿")

            for idx, row in gdf.iterrows():
                # P34_003: å½¹å ´åç§°, P34_004: ä½æ‰€
                city_name = row['P34_003'].replace('å½¹æ‰€', '').replace('å½¹å ´', '')
                address = row['P34_004']
                lon = row.geometry.x
                lat = row.geometry.y

                all_data.append({
                    'prefecture_code': pref_num,
                    'city_name': city_name,
                    'address': address,
                    'longitude': lon,
                    'latitude': lat
                })

        except Exception as e:
            print(f"âœ— {pref_dir.name}: ã‚¨ãƒ©ãƒ¼ - {e}")

    print(f"\nâœ… åˆè¨ˆ {len(all_data)}ä»¶ã®ãƒ‡ãƒ¼ã‚¿ã‚’æŠ½å‡º\n")
    return pd.DataFrame(all_data)

def save_outputs(df):
    """çµæœã‚’ä¿å­˜"""
    print("=" * 70)
    print("å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«ç”Ÿæˆ")
    print("=" * 70)

    # CSVå‡ºåŠ›
    csv_path = OUTPUT_DIR / 'all_city_halls.csv'
    df.to_csv(csv_path, index=False, encoding='utf-8-sig')
    print(f"âœ… CSV: {csv_path}")

    # çµ±è¨ˆæƒ…å ±
    print(f"\nğŸ“Š éƒ½é“åºœçœŒåˆ¥ãƒ‡ãƒ¼ã‚¿æ•°:")
    pref_counts = df['prefecture_code'].value_counts().sort_index()
    for pref_code, count in pref_counts.items():
        print(f"   {pref_code}: {count}ä»¶")

    # ç£ç”°å¸‚ã®åº§æ¨™ã‚’ç¢ºèª
    print(f"\nğŸ” ç£ç”°å¸‚ã®åº§æ¨™:")
    iwata = df[df['city_name'].str.contains('ç£ç”°å¸‚')]
    if len(iwata) > 0:
        for idx, row in iwata.iterrows():
            print(f"   {row['city_name']}")
            print(f"   ä½æ‰€: {row['address']}")
            print(f"   åº§æ¨™: [{row['longitude']}, {row['latitude']}]")
            print(f"   ç¾åœ¨ã®è¨­å®šå€¤: [137.8515211, 34.717837]")
            print(f"   å·®åˆ†: çµŒåº¦ {abs(row['longitude'] - 137.8515211):.6f}, ç·¯åº¦ {abs(row['latitude'] - 34.717837):.6f}")

    # Pythonè¾æ›¸å½¢å¼ã§ä¸»è¦å¸‚ã®ã¿å‡ºåŠ›ï¼ˆäººå£3ä¸‡ä»¥ä¸Šã«å¯¾å¿œï¼‰
    print(f"\nğŸ“ ä¸»è¦å¸‚ãƒ‡ãƒ¼ã‚¿ç”¨ã®è¾æ›¸ã‚’ç”Ÿæˆä¸­...")

    # å¸‚åã‹ã‚‰åº§æ¨™ã‚’å¼•ã‘ã‚‹ã‚ˆã†ã«ã™ã‚‹
    city_coords = {}
    for idx, row in df.iterrows():
        # "ã€‡ã€‡å¸‚", "ã€‡ã€‡ç”º", "ã€‡ã€‡æ‘" ã‚’æŠ½å‡º
        city_name = row['city_name']

        # æ—¢ã«ã‚ã‚‹å¸‚åã¯ä¸Šæ›¸ãã—ãªã„ï¼ˆæœ€åˆã®ã‚¨ãƒ³ãƒˆãƒªã‚’å„ªå…ˆï¼‰
        if city_name not in city_coords:
            city_coords[city_name] = {
                'center': [row['longitude'], row['latitude']],
                'address': row['address']
            }

    # Pythonè¾æ›¸ãƒ•ã‚¡ã‚¤ãƒ«ç”Ÿæˆ
    py_path = OUTPUT_DIR / 'all_city_halls_dict.py'
    with open(py_path, 'w', encoding='utf-8') as f:
        f.write('"""\\n')
        f.write('å…¨å›½å¸‚åŒºç”ºæ‘å½¹å ´åº§æ¨™ãƒ‡ãƒ¼ã‚¿\\n')
        f.write('\\n')
        f.write('å‡ºå…¸: å›½åœŸæ•°å€¤æƒ…å ± å¸‚ç”ºæ‘å½¹å ´ãƒ‡ãƒ¼ã‚¿ï¼ˆ2014å¹´åº¦ï¼‰\\n')
        f.write('URL: https://nlftp.mlit.go.jp/ksj/gml/datalist/KsjTmplt-P34.html\\n')
        f.write('åº§æ¨™ç³»: ä¸–ç•Œæ¸¬åœ°ç³»ï¼ˆWGS84ï¼‰\\n')
        f.write('å½¢å¼: [çµŒåº¦, ç·¯åº¦] (GeoJSONå½¢å¼)\\n')
        f.write('"""\\n\\n')
        f.write('CITY_HALL_COORDINATES = {\\n')

        for city_name in sorted(city_coords.keys()):
            coords = city_coords[city_name]
            lon, lat = coords['center']
            f.write(f'    "{city_name}": {{"center": [{lon:.7f}, {lat:.7f}]}},\\n')

        f.write('}\\n')

    print(f"âœ… Pythonè¾æ›¸: {py_path}")
    print(f"   {len(city_coords)}å€‹ã®å¸‚åŒºç”ºæ‘")

def main():
    print("\\nğŸ—¾ å…¨å›½å¸‚åŒºç”ºæ‘å½¹å ´åº§æ¨™çµ±åˆå‡¦ç†\\n")

    # 1. ZIPè§£å‡
    extract_dir = extract_all_zips()

    # 2. åº§æ¨™æŠ½å‡º
    df = extract_coordinates_from_shapefiles(extract_dir)

    # 3. å‡ºåŠ›
    save_outputs(df)

    print("\\n" + "=" * 70)
    print("âœ… å‡¦ç†å®Œäº†")
    print("=" * 70)

if __name__ == '__main__':
    main()
